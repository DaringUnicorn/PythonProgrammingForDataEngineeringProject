{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValueHandler:\n",
    "    \"\"\"\n",
    "    The MissingValueHandler class provides methods to handle missing values.\n",
    "\n",
    "    Attributes:\n",
    "        data (DataFrame): The dataset to be processed.\n",
    "\n",
    "    Methods:\n",
    "        fill_missing_values_with_mean(columns=None): Fills missing values with column means.\n",
    "        fill_missing_values_with_median(columns=None): Fills missing values with column medians.\n",
    "        fill_missing_values_with_constant(constant, columns=None): Fills missing values with the specified constant.\n",
    "        delete_missing_values(columns=None): Deletes rows containing missing values from the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Constructor method for the MissingValueHandler class.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): The dataset to be processed.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def fillingWithMean(self, columns=None):\n",
    "        \"\"\"\n",
    "        Fills missing values with column means.\n",
    "\n",
    "        Args:\n",
    "            columns (list, optional): The columns to operate on. By default, all columns are used.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data.fillna(self.data.mean(), inplace=True, subset=columns)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while filling missing values with mean: {e}\")\n",
    "\n",
    "    def fillingWithMedian(self, columns=None):\n",
    "        \"\"\"\n",
    "        Fills missing values with column medians.\n",
    "\n",
    "        Args:\n",
    "            columns (list, optional): The columns to operate on. By default, all columns are used.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data.fillna(self.data.median(), inplace=True, subset=columns)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while filling missing values with median: {e}\")\n",
    "\n",
    "    def filingWithConstant(self, constant, columns=None):\n",
    "        \"\"\"\n",
    "        Fills missing values with the specified constant.\n",
    "\n",
    "        Args:\n",
    "            constant: The constant value to fill missing values with.\n",
    "            columns (list, optional): The columns to operate on. By default, all columns are used.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data.fillna(constant, inplace=True, subset=columns)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while filling missing values with constant: {e}\")\n",
    "\n",
    "    def deletingMissingValues(self, columns=None):\n",
    "        \"\"\"\n",
    "        Deletes rows containing missing values from the dataset.\n",
    "\n",
    "        Args:\n",
    "            columns (list, optional): The columns to operate on. By default, all columns are used.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data.dropna(inplace=True, subset=columns)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while deleting missing values: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierHandler:\n",
    "    \"\"\"\n",
    "    A class to handle outliers in a dataset using the Interquartile Range (IQR) method.\n",
    "\n",
    "    Attributes:\n",
    "        data (DataFrame): The input DataFrame containing the dataset.\n",
    "        \n",
    "    Methods:\n",
    "        handle_outliers_iqr(column, threshold=1.5):\n",
    "            Handle outliers in the specified column using the IQR method.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initializes the OutlierHandler with the input dataset.\n",
    "\n",
    "        Parameters:\n",
    "            data (DataFrame): The input DataFrame containing the dataset.\n",
    "        \"\"\"\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input data must be a pandas DataFrame.\")\n",
    "        self.data = data\n",
    "\n",
    "    def handlingOutliersIqr(self, column, threshold=1.5):\n",
    "        \"\"\"\n",
    "        Handles outliers in the specified column using the Interquartile Range (IQR) method.\n",
    "\n",
    "        Outliers are identified based on the IQR score of the column.\n",
    "        Data points lying beyond the threshold times the IQR above the third quartile\n",
    "        or below the first quartile are considered outliers and removed from the dataset.\n",
    "\n",
    "        Parameters:\n",
    "            column (str): The name of the column to handle outliers.\n",
    "            threshold (float, optional): The threshold multiplier for defining outliers.\n",
    "                Default is 1.5.\n",
    "\n",
    "        Returns:\n",
    "            None. Modifies the data attribute in-place by removing outliers from the specified column.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            q1 = self.data[column].quantile(0.25)\n",
    "            q3 = self.data[column].quantile(0.75)\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Column '{column}' does not exist in the dataset.\")\n",
    "\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - threshold * iqr\n",
    "        upper_bound = q3 + threshold * iqr\n",
    "\n",
    "        try:\n",
    "            self.data = self.data[(self.data[column] >= lower_bound) & (self.data[column] <= upper_bound)]\n",
    "        except KeyError:\n",
    "            raise KeyError(f\"Column '{column}' does not exist in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler:\n",
    "    \"\"\"\n",
    "    A class for scaling numerical data using Min-Max scaling and Standard scaling methods.\n",
    "    \n",
    "    Attributes:\n",
    "        data (DataFrame): The input DataFrame containing numerical data to be scaled.\n",
    "    \n",
    "    Methods:\n",
    "        min_max_scaling(columns):\n",
    "            Scale the specified numerical columns using Min-Max scaling method.\n",
    "        \n",
    "        standard_scaling(columns):\n",
    "            Scale the specified numerical columns using Standard scaling method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initialize the Scaler object with the input DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): The input DataFrame containing numerical data.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def minMaxScaling(self, columns):\n",
    "        \"\"\"\n",
    "        Scale the specified numerical columns using Min-Max scaling method.\n",
    "\n",
    "        Args:\n",
    "            columns (list): A list of column names to be scaled.\n",
    "\n",
    "        Returns:\n",
    "            None. Modifies the DataFrame in-place.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If any column specified in `columns` does not exist in the DataFrame.\n",
    "            ZeroDivisionError: If attempting to perform Min-Max scaling and the range of a column is zero.\n",
    "        \"\"\"\n",
    "        for column in columns:\n",
    "            if column not in self.data.columns:\n",
    "                raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "            min_val = self.data[column].min()\n",
    "            max_val = self.data[column].max()\n",
    "            if min_val == max_val:\n",
    "                raise ZeroDivisionError(f\"Cannot perform Min-Max scaling on column '{column}' because the range is zero.\")\n",
    "            self.data[column] = (self.data[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "    def standardScaling(self, columns):\n",
    "        \"\"\"\n",
    "        Scale the specified numerical columns using Standard scaling method.\n",
    "\n",
    "        Args:\n",
    "            columns (list): A list of column names to be scaled.\n",
    "\n",
    "        Returns:\n",
    "            None. Modifies the DataFrame in-place.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If any column specified in `columns` does not exist in the DataFrame.\n",
    "            ZeroDivisionError: If attempting to perform Standard scaling and the standard deviation of a column is zero.\n",
    "        \"\"\"\n",
    "        for column in columns:\n",
    "            if column not in self.data.columns:\n",
    "                raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "            mean_val = self.data[column].mean()\n",
    "            std_val = self.data[column].std()\n",
    "            if std_val == 0:\n",
    "                raise ZeroDivisionError(f\"Cannot perform Standard scaling on column '{column}' because the standard deviation is zero.\")\n",
    "            self.data[column] = (self.data[column] - mean_val) / std_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextCleaner:\n",
    "    \"\"\"\n",
    "    A class to perform text cleaning operations on a pandas DataFrame column.\n",
    "\n",
    "    Attributes:\n",
    "        data (pandas.DataFrame): The DataFrame containing the text data.\n",
    "\n",
    "    Methods:\n",
    "        remove_stopwords(column):\n",
    "            Removes stopwords from the specified column using NLTK's English stopwords list.\n",
    "            Args:\n",
    "                column (str): The name of the column containing text data.\n",
    "\n",
    "        lowercase_text(column):\n",
    "            Converts text in the specified column to lowercase.\n",
    "            Args:\n",
    "                column (str): The name of the column containing text data.\n",
    "\n",
    "        remove_punctuation(column):\n",
    "            Removes punctuation from the specified column.\n",
    "            Args:\n",
    "                column (str): The name of the column containing text data.\n",
    "\n",
    "        lemmatize_text(column):\n",
    "            Lemmatizes the text in the specified column using NLTK's WordNetLemmatizer.\n",
    "            Args:\n",
    "                column (str): The name of the column containing text data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initializes the TextCleaner object with the provided DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data (pandas.DataFrame): The DataFrame containing the text data.\n",
    "        \"\"\"\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input data must be a pandas DataFrame.\")\n",
    "        self.data = data\n",
    "\n",
    "    def removeStopwords(self, column):\n",
    "        \"\"\"\n",
    "        Removes stopwords from the specified column using NLTK's English stopwords list.\n",
    "\n",
    "        Args:\n",
    "            column (str): The name of the column containing text data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            self.data[column] = self.data[column].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\n",
    "        except LookupError:\n",
    "            nltk.download('stopwords')\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            self.data[column] = self.data[column].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))\n",
    "\n",
    "    def lowercaseText(self, column):\n",
    "        \"\"\"\n",
    "        Converts text in the specified column to lowercase.\n",
    "\n",
    "        Args:\n",
    "            column (str): The name of the column containing text data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data[column] = self.data[column].str.lower()\n",
    "        except AttributeError:\n",
    "            raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "    def removePunctuation(self, column):\n",
    "        \"\"\"\n",
    "        Removes punctuation from the specified column.\n",
    "\n",
    "        Args:\n",
    "            column (str): The name of the column containing text data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data[column] = self.data[column].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "        except AttributeError:\n",
    "            raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "    def lemmatizeText(self, column):\n",
    "        \"\"\"\n",
    "        Lemmatizes the text in the specified column using NLTK's WordNetLemmatizer.\n",
    "\n",
    "        Args:\n",
    "            column (str): The name of the column containing text data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            self.data[column] = self.data[column].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(x)]))\n",
    "        except LookupError:\n",
    "            nltk.download('wordnet')\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            self.data[column] = self.data[column].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(x)]))\n",
    "        except AttributeError:\n",
    "            raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer:\n",
    "    \"\"\"\n",
    "    A class for feature engineering tasks on a given dataset.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        The input DataFrame containing the data to be engineered.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    create_new_features():\n",
    "        Creates new features based on existing ones. \n",
    "        Generates 'total_sales' by multiplying 'product_price' and 'quantity', \n",
    "        and 'age_category' by categorizing 'age' into predefined bins.\n",
    "\n",
    "    calculate_percentage():\n",
    "        Calculates the percentage of individual sales with respect to total sales.\n",
    "        Requires 'individual_sales' and 'total_sales' columns to be present.\n",
    "\n",
    "    normalize_features(columns):\n",
    "        Normalizes specified numerical features in the dataset.\n",
    "        The normalization is done by scaling the values between 0 and 1.\n",
    "\n",
    "    create_interaction_terms(feature1, feature2):\n",
    "        Creates interaction terms between two specified features.\n",
    "        Generates a new feature representing the product of the given features.\n",
    "\n",
    "    detect_weekend(date_column):\n",
    "        Detects whether each date in the specified column falls on a weekend.\n",
    "        Adds a binary column 'is_weekend' indicating if the date is a weekend day (1) or not (0).\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initializes the FeatureEngineer object with the provided data.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pandas.DataFrame\n",
    "            The input DataFrame containing the data to be engineered.\n",
    "        \"\"\"\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input data must be a pandas DataFrame.\")\n",
    "        self.data = data\n",
    "\n",
    "    def createNewFeatures(self):\n",
    "        \"\"\"\n",
    "        Creates new features based on existing ones.\n",
    "        Generates 'total_sales' by multiplying 'product_price' and 'quantity', \n",
    "        and 'age_category' by categorizing 'age' into predefined bins.\n",
    "        \"\"\"\n",
    "        if {'product_price', 'quantity', 'age'}.issubset(self.data.columns):\n",
    "            self.data['total_sales'] = self.data['product_price'] * self.data['quantity']\n",
    "            self.data['age_category'] = pd.cut(self.data['age'], bins=[0, 18, 30, 50, np.inf], labels=['0-18', '19-30', '31-50', '51+'])\n",
    "        else:\n",
    "            raise ValueError(\"Columns 'product_price', 'quantity', and 'age' are required for feature creation.\")\n",
    "\n",
    "    def calculatePercentage(self):\n",
    "        \"\"\"\n",
    "        Calculates the percentage of individual sales with respect to total sales.\n",
    "        Requires 'individual_sales' and 'total_sales' columns to be present.\n",
    "        \"\"\"\n",
    "        if {'individual_sales', 'total_sales'}.issubset(self.data.columns):\n",
    "            self.data['percentage_of_total'] = (self.data['individual_sales'] / self.data['total_sales']) * 100\n",
    "        else:\n",
    "            raise ValueError(\"Columns 'individual_sales' and 'total_sales' are required for percentage calculation.\")\n",
    "\n",
    "    def normalizeFeatures(self, columns):\n",
    "        \"\"\"\n",
    "        Normalizes specified numerical features in the dataset.\n",
    "        The normalization is done by scaling the values between 0 and 1.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        columns : list\n",
    "            A list of column names to be normalized.\n",
    "        \"\"\"\n",
    "        for column in columns:\n",
    "            if column not in self.data.columns:\n",
    "                raise ValueError(f\"Column '{column}' not found in the dataset.\")\n",
    "            self.data[f'{column}_normalized'] = (self.data[column] - self.data[column].min()) / (self.data[column].max() - self.data[column].min())\n",
    "\n",
    "    def createInteractionTerms(self, feature1, feature2):\n",
    "        \"\"\"\n",
    "        Creates interaction terms between two specified features.\n",
    "        Generates a new feature representing the product of the given features.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        feature1 : str\n",
    "            Name of the first feature.\n",
    "        feature2 : str\n",
    "            Name of the second feature.\n",
    "        \"\"\"\n",
    "        if {feature1, feature2}.issubset(self.data.columns):\n",
    "            self.data[f'{feature1}_{feature2}_interaction'] = self.data[feature1] * self.data[feature2]\n",
    "        else:\n",
    "            raise ValueError(f\"Columns '{feature1}' and '{feature2}' are required for interaction term creation.\")\n",
    "\n",
    "    def detectWeekend(self, date_column):\n",
    "        \"\"\"\n",
    "        Detects whether each date in the specified column falls on a weekend.\n",
    "        Adds a binary column 'is_weekend' indicating if the date is a weekend day (1) or not (0).\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        date_column : str\n",
    "            Name of the column containing date values.\n",
    "        \"\"\"\n",
    "        if date_column not in self.data.columns:\n",
    "            raise ValueError(f\"Column '{date_column}' not found in the dataset.\")\n",
    "        self.data['is_weekend'] = self.data[date_column].dt.dayofweek // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTypeConverter:\n",
    "    \"\"\"\n",
    "    A class for converting data types of columns in a pandas DataFrame.\n",
    "\n",
    "    Attributes:\n",
    "        data (DataFrame): The input DataFrame containing the data to be converted.\n",
    "\n",
    "    Methods:\n",
    "        convert_to_numeric: Converts specified columns to numeric data type.\n",
    "        convert_to_categorical: Converts specified columns to categorical data type.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initializes the DataTypeConverter with the input DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): The input DataFrame containing the data to be converted.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def convertNumeric(self, columns):\n",
    "        \"\"\"\n",
    "        Converts specified columns to numeric data type.\n",
    "\n",
    "        Args:\n",
    "            columns (list): A list of column names to be converted to numeric data type.\n",
    "        \"\"\"\n",
    "        self.data[columns] = self.data[columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    def convertToCategorical(self, columns):\n",
    "        \"\"\"\n",
    "        Converts specified columns to categorical data type.\n",
    "\n",
    "        Args:\n",
    "            columns (list): A list of column names to be converted to categorical data type.\n",
    "        \"\"\"\n",
    "        self.data[columns] = self.data[columns].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CategoricalEncoder:\n",
    "    \"\"\"\n",
    "    A class for encoding categorical variables in a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame\n",
    "        The DataFrame containing the categorical variables to be encoded.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    one_hot_encode(columns):\n",
    "        Encode categorical variables using one-hot encoding.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        columns : list\n",
    "            A list of column names containing categorical variables to be one-hot encoded.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None. Updates the DataFrame in-place with one-hot encoded columns.\n",
    "\n",
    "    label_encode(columns):\n",
    "        Encode categorical variables using label encoding.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        columns : list\n",
    "            A list of column names containing categorical variables to be label encoded.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None. Updates the DataFrame in-place with label encoded columns.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initialize the CategoricalEncoder object with a pandas DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pandas DataFrame\n",
    "            The DataFrame containing the categorical variables to be encoded.\n",
    "        \"\"\"\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            raise ValueError(\"Input data must be a pandas DataFrame.\")\n",
    "        self.data = data\n",
    "\n",
    "    def oneHotEncode(self, columns):\n",
    "        \"\"\"\n",
    "        Encode categorical variables using one-hot encoding.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        columns : list\n",
    "            A list of column names containing categorical variables to be one-hot encoded.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None. Updates the DataFrame in-place with one-hot encoded columns.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data = pd.get_dummies(self.data, columns=columns)\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: One or more specified columns {e} not found in the DataFrame.\")\n",
    "\n",
    "    def labelEncode(self, columns):\n",
    "        \"\"\"\n",
    "        Encode categorical variables using label encoding.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        columns : list\n",
    "            A list of column names containing categorical variables to be label encoded.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        None. Updates the DataFrame in-place with label encoded columns.\n",
    "        \"\"\"\n",
    "        label_encoder = LabelEncoder()\n",
    "        try:\n",
    "            for column in columns:\n",
    "                self.data[column] = label_encoder.fit_transform(self.data[column])\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: One or more specified columns {e} not found in the DataFrame.\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: Unable to perform label encoding. {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DateTimeHandler:\n",
    "    \"\"\"\n",
    "    A class to handle date and time features extraction from a DataFrame.\n",
    "\n",
    "    Attributes:\n",
    "        data (DataFrame): The DataFrame containing the date and time column.\n",
    "\n",
    "    Methods:\n",
    "        extract_date_features(column): Extracts various date and time features from the specified column \n",
    "                                        and adds them as new columns to the DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initializes the DateTimeHandler object with the provided DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): The DataFrame containing the date and time column.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "\n",
    "    def extractDateFeatures(self, column):\n",
    "        \"\"\"\n",
    "        Extracts various date and time features from the specified column and adds them as new columns to the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            column (str): The name of the column containing the date and time information.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If the specified column does not exist in the DataFrame.\n",
    "            TypeError: If the data type of the specified column is not compatible with datetime conversion.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Convert the specified column to datetime\n",
    "            self.data[column] = pd.to_datetime(self.data[column])\n",
    "\n",
    "            # Extract year, month, day, day of week, hour, and minute features\n",
    "            self.data['year'] = self.data[column].dt.year\n",
    "            self.data['month'] = self.data[column].dt.month\n",
    "            self.data['day'] = self.data[column].dt.day\n",
    "            self.data['day_of_week'] = self.data[column].dt.dayofweek  # Weekday (0: Monday, 1: Tuesday, ..., 6: Sunday)\n",
    "            self.data['hour'] = self.data[column].dt.hour  # Hour\n",
    "            self.data['minute'] = self.data[column].dt.minute  # Minute\n",
    "\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "        except TypeError:\n",
    "            raise TypeError(\"The data type of the specified column is not compatible with datetime conversion.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
